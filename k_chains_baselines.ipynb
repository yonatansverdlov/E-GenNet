{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yonatansverdlov/E-GenNet/blob/master/k_chains_baselines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9vrEsxpYnlV"
      },
      "source": [
        "\n",
        "# Disseminating geometric data: $k$-chains\n",
        "Context:\n",
        "In geometric graph neural networks (GNNs), the transmission of geometric data, like the relative positioning of local neighborhoods, occurs through the aggregation of features across multiple layers within fixed-dimensional spaces. Ideally, an architecture capable of operating across any number of layers would perfectly transmit geometric data without any loss. However, in practice, stacking geometric GNN layers can introduce distortions or result in the loss of information from distant nodes.\n",
        "\n",
        "Experimental Setup:\n",
        "To investigate the practical implications of depth in transmitting geometric information beyond local neighborhoods, we examine $k$-chain geometric graphs, a concept extending from examples discussed in Schütt et al., 2021. Each $k$-chain consists of $k+2$ nodes, with $k$ nodes arranged linearly and distinguished by the orientation of the $2$ endpoints. Consequently, $k$-chain graphs are $(\\lfloor \\frac{k}{2} \\rfloor + 1)$-hop distinguishable, and theoretically, $(\\lfloor \\frac{k}{2} \\rfloor + 1)$ iterations of geometric GNNs should suffice for their discrimination. Within this study, we train equivariant and invariant geometric GNNs, increasing the number of layers, to differentiate $k$-chains.\n",
        "\n",
        "Additionally, we explore the impact of power graphs in scenarios where I-GGNNs are unable to distinguish between graphs. Specifically, we examine pairs of graphs depicted in the figure. In Pair A, theoretically, there is insufficient information to distinguish between $G_{1}$ and $G_{2}$, but there is adequate information in $G_{1}^{2}$ and $G_{2}^{2}$. In Pair B, theoretically, there is insufficient information to distinguish between $(G_{1}, G_{2})$ and $(G_{1}^{2}, G_{2}^{2})$, but there is adequate information in $(G_{1}^{3}, G_{2}^{3})$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "MRHVAc977fJx",
        "outputId": "3828d35f-ce5f-49e6-fdbb-826a268df2b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'plot_utils'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dc8195c71b86>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/k_chain_exps/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplot_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plot_utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "drive.mount('/content/drive')\n",
        "# We expact the k_chain_exps directory to be in that place.\n",
        "sys.path.append('/content/drive/MyDrive/k_chain_exps/')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Packages."
      ],
      "metadata": {
        "id": "7QoUhPwJ6Bwm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqIeByYsapfb"
      },
      "outputs": [],
      "source": [
        "# Add this in a Google Colab cell to install the correct version of Pytorch Geometric.\n",
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric\n",
        "!pip install e3nn==0.4.4 ipdb ase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-blRgMtmIVzO"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KZ9oXthIadX"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HE4xlTGwoXqe"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "import torch_geometric.loader as loader\n",
        "from torch_geometric.utils import to_undirected\n",
        "import e3nn\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "\n",
        "print(\"PyTorch version {}\".format(torch.__version__))\n",
        "print(\"PyG version {}\".format(torch_geometric.__version__))\n",
        "print(\"e3nn version {}\".format(e3nn.__version__))\n",
        "\n",
        "from experiments.utils.plot_utils import plot_2d, plot_3d\n",
        "from experiments.utils.data import create_kchains,create_pairA,create_pairB\n",
        "from experiments.utils.train_utils import run_experiment\n",
        "from models.schnet import SchNetModel\n",
        "from models.dimenet import DimeNetPPModel\n",
        "from models.spherenet import SphereNetModel\n",
        "from models.egnn import EGNNModel\n",
        "from models.gvpgnn import GVPGNNModel\n",
        "from models.tfn import TFNModel\n",
        "from models.mace import MACEModel\n",
        "# Set the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pl9qBnAm7Z6"
      },
      "source": [
        "# Propogating geometric information: $k$-chains\n",
        "In the first set of experiments we test the original $k$-chains for  $k$=12. Our aim is to examine long dependences of several models.\n",
        "For that we run the desired model with increasing number of blocks and report the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WApjQ_RroXqg"
      },
      "outputs": [],
      "source": [
        "k = 12\n",
        "ntimes = 10\n",
        "\n",
        "# Create dataset\n",
        "dataset = create_kchains(k=k)\n",
        "for data in dataset:\n",
        "    plot_2d(data, lim=60)\n",
        "\n",
        "# Create dataloaders\n",
        "dataloader = loader.DataLoader(dataset, batch_size=1)\n",
        "val_loader = loader.DataLoader(dataset, batch_size=1)\n",
        "test_loader = loader.DataLoader(dataset, batch_size=1)\n",
        "# Set model\n",
        "model_name = \"EGNN\"\n",
        "\n",
        "for num_layers in range(10 , 12):\n",
        "\n",
        "    correlation = 2\n",
        "    model = {\n",
        "        \"SchNet\": SchNetModel,\n",
        "        \"dimenet\": DimeNetPPModel,\n",
        "        \"spherenet\": SphereNetModel,\n",
        "        \"EGNN\": EGNNModel,\n",
        "        \"GVP\": partial(GVPGNNModel, s_dim=32, v_dim=1),\n",
        "        \"TFN\": TFNModel,\n",
        "        \"MACE\": partial(MACEModel, correlation=correlation),\n",
        "    }[model_name](num_layers=num_layers, in_dim=1, out_dim=2)\n",
        "\n",
        "    best_val_acc_list, test_acc_list, train_time_list = run_experiment(\n",
        "        model,\n",
        "        dataloader,\n",
        "        val_loader,\n",
        "        test_loader,\n",
        "        n_epochs=150,\n",
        "        n_times=ntimes,\n",
        "        device=device,\n",
        "        verbose=False\n",
        "    )\n",
        "    print(f'\\nDone! Averaged over {ntimes} runs of {model_name} with {num_layers} layers: \\n '\n",
        "          f'- Training time: {np.mean(train_time_list):.2f}s ± {np.std(train_time_list):.2f}. \\n '\n",
        "          f'- Best validation accuracy: {np.mean(best_val_acc_list):.3f} ± {np.std(best_val_acc_list):.2f}. \\n'\n",
        "          f'- Test accuracy: {np.mean(test_acc_list):.1f} ± {np.std(test_acc_list):.1f}. \\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHJIDDK5Inm3"
      },
      "source": [
        "# Pairs seperation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8A03vrQJaB7"
      },
      "source": [
        "# Pair A.\n",
        "In this section, we show the seperation ability of the model depending on the power graph. In this experiment, we show no I-GGNN can sepearte the first power $G^{1}$, but can $G^{2}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DpfG6gIoXqg"
      },
      "outputs": [],
      "source": [
        "ntimes= 10\n",
        "k = 12\n",
        "\n",
        "# Create dataset\n",
        "for power in [1,2]:\n",
        "  dataset = create_pairA(k=k,power = power)\n",
        "  print(f\"The graph power {power}\")\n",
        "  for data in dataset:\n",
        "      plot_2d(data, lim=6.0)\n",
        "\n",
        "  # Create dataloaders\n",
        "  dataloader = loader.DataLoader(dataset, batch_size=1)\n",
        "  val_loader = loader.DataLoader(dataset, batch_size=1)\n",
        "  test_loader = loader.DataLoader(dataset, batch_size=1)\n",
        "  # Set model\n",
        "  model_name = \"schnet\"\n",
        "\n",
        "  for num_layers in range(5 , 7):\n",
        "\n",
        "      print(f\"\\nNumber of layers: {num_layers}\")\n",
        "\n",
        "      correlation = 2\n",
        "      model = {\n",
        "          \"schnet\": SchNetModel,\n",
        "          \"dimenet\": DimeNetPPModel,\n",
        "          \"spherenet\": SphereNetModel,\n",
        "          \"egnn\": EGNNModel,\n",
        "          \"gvp\": partial(GVPGNNModel, s_dim=32, v_dim=1),\n",
        "          \"tfn\": TFNModel,\n",
        "          \"mace\": partial(MACEModel, correlation=correlation),\n",
        "      }[model_name](num_layers=num_layers, in_dim=1, out_dim=2)\n",
        "\n",
        "      best_val_acc_list, test_acc_list, train_time_list = run_experiment(\n",
        "        model,\n",
        "        dataloader,\n",
        "        val_loader,\n",
        "        test_loader,\n",
        "        n_epochs=150,\n",
        "        n_times=ntimes,\n",
        "        device=device,\n",
        "        verbose=False\n",
        "    )\n",
        "      print(f'\\nDone! Averaged over {ntimes} runs of {model_name} with {num_layers} layers, power graph {power}: \\n '\n",
        "          f'- Training time: {np.mean(train_time_list):.2f}s ± {np.std(train_time_list):.2f}. \\n '\n",
        "          f'- Best validation accuracy: {np.mean(best_val_acc_list):.3f} ± {np.std(best_val_acc_list):.3f}. \\n'\n",
        "          f'- Test accuracy: {np.mean(test_acc_list):.1f} ± {np.std(test_acc_list):.1f}. \\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5yt2WVwJQpX"
      },
      "source": [
        "# Pair B\n",
        "In this section, we show the seperation ability of the model depending on the power graph. In this experiment, we show no I-GGNN can sepearte the first power and second but third could be separated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixrPtEw3JQ4e"
      },
      "outputs": [],
      "source": [
        "ntimes= 10\n",
        "k = 12\n",
        "\n",
        "# Create dataset\n",
        "for power in [1,2,3]:\n",
        "  dataset = create_pairB(k=k,power = power)\n",
        "  print(f\"The graph power {power}\")\n",
        "  for data in dataset:\n",
        "      plot_2d(data, lim=6.0)\n",
        "\n",
        "  # Create dataloaders\n",
        "  dataloader = loader.DataLoader(dataset, batch_size=1)\n",
        "  val_loader = loader.DataLoader(dataset, batch_size=1)\n",
        "  test_loader = loader.DataLoader(dataset, batch_size=1)\n",
        "  # Set model\n",
        "  model_name = \"schnet\"\n",
        "\n",
        "  for num_layers in range(5 , 7):\n",
        "\n",
        "      print(f\"\\nNumber of layers: {num_layers}\")\n",
        "\n",
        "      correlation = 2\n",
        "      model = {\n",
        "          \"schnet\": SchNetModel,\n",
        "          \"dimenet\": DimeNetPPModel,\n",
        "          \"spherenet\": SphereNetModel,\n",
        "          \"egnn\": EGNNModel,\n",
        "          \"gvp\": partial(GVPGNNModel, s_dim=32, v_dim=1),\n",
        "          \"tfn\": TFNModel,\n",
        "          \"mace\": partial(MACEModel, correlation=correlation),\n",
        "      }[model_name](num_layers=num_layers, in_dim=1, out_dim=2)\n",
        "\n",
        "      best_val_acc_list, test_acc_list, train_time_list = run_experiment(\n",
        "        model,\n",
        "        dataloader,\n",
        "        val_loader,\n",
        "        test_loader,\n",
        "        n_epochs=150,\n",
        "        n_times=ntimes,\n",
        "        device=device,\n",
        "        verbose=False\n",
        "    )\n",
        "      print(f'\\nDone! Averaged over {ntimes} runs of {model_name} with {num_layers} layers, power graph {power}: \\n '\n",
        "          f'- Training time: {np.mean(train_time_list):.2f}s ± {np.std(train_time_list):.2f}. \\n '\n",
        "          f'- Best validation accuracy: {np.mean(best_val_acc_list):.3f} ± {np.std(best_val_acc_list):.3f}. \\n'\n",
        "          f'- Test accuracy: {np.mean(test_acc_list):.1f} ± {np.std(test_acc_list):.1f}. \\n')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "94aa676993820a604ac86f7af94f5432e989a749d5dd43e18f9507de2e8c2897"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}