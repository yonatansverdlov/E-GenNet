{
<<<<<<< HEAD
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yonatansverdlov/E-GenNet/blob/master/k_chains_baselines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9vrEsxpYnlV"
      },
      "source": [
        "\n",
        "# Disseminating geometric data: $k$-chains\n",
        "Context:\n",
        "In geometric graph neural networks (GNNs), the transmission of geometric data, like the relative positioning of local neighborhoods, occurs through the aggregation of features across multiple layers within fixed-dimensional spaces. Ideally, an architecture capable of operating across any number of layers would perfectly transmit geometric data without any loss. However, in practice, stacking geometric GNN layers can introduce distortions or result in the loss of information from distant nodes.\n",
        "\n",
        "Experimental Setup:\n",
        "To investigate the practical implications of depth in transmitting geometric information beyond local neighborhoods, we examine $k$-chain geometric graphs, a concept extending from examples discussed in Schütt et al., 2021. Each $k$-chain consists of $k+2$ nodes, with $k$ nodes arranged linearly and distinguished by the orientation of the $2$ endpoints. Consequently, $k$-chain graphs are $(\\lfloor \\frac{k}{2} \\rfloor + 1)$-hop distinguishable, and theoretically, $(\\lfloor \\frac{k}{2} \\rfloor + 1)$ iterations of geometric GNNs should suffice for their discrimination. Within this study, we train equivariant and invariant geometric GNNs, increasing the number of layers, to differentiate $k$-chains.\n",
        "\n",
        "Additionally, we explore the impact of power graphs in scenarios where I-GGNNs are unable to distinguish between graphs. Specifically, we examine pairs of graphs depicted in the figure. In Pair A, theoretically, there is insufficient information to distinguish between $G_{1}$ and $G_{2}$, but there is adequate information in $G_{1}^{2}$ and $G_{2}^{2}$. In Pair B, theoretically, there is insufficient information to distinguish between $(G_{1}, G_{2})$ and $(G_{1}^{2}, G_{2}^{2})$, but there is adequate information in $(G_{1}^{3}, G_{2}^{3})$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRHVAc977fJx",
        "outputId": "cb15c9c4-90c7-4b9f-a527-46b58b1a5ceb"
      },
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "drive.mount('/content/drive')\n",
        "# We expact the k_chain_exps directory to be in that place.\n",
        "\n",
        "!git clone https://github.com/yonatansverdlov/E-GenNet\n",
        "sys.path.append('/content/E-GenNet/k_chain_exps')\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'E-GenNet'...\n",
            "remote: Enumerating objects: 656, done.\u001b[K\n",
            "remote: Counting objects: 100% (325/325), done.\u001b[K\n",
            "remote: Compressing objects: 100% (238/238), done.\u001b[K\n",
            "remote: Total 656 (delta 174), reused 200 (delta 82), pack-reused 331 (from 1)\u001b[K\n",
            "Receiving objects: 100% (656/656), 1.76 MiB | 15.49 MiB/s, done.\n",
            "Resolving deltas: 100% (351/351), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Packages."
      ],
      "metadata": {
        "id": "7QoUhPwJ6Bwm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HqIeByYsapfb",
        "collapsed": true,
        "outputId": "ed57e4b4-e51d-4663-bb63-d714f3618f88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Add this in a Google Colab cell to install the correct version of Pytorch Geometric.\n",
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric\n",
        "!pip install e3nn\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.5.0+cu121.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/torch_scatter-2.1.2%2Bpt25cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt25cu121\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.5.0+cu121.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/torch_sparse-0.6.18%2Bpt25cu121-cp310-cp310-linux_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt25cu121\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.5.0+cu121.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/torch_cluster-1.6.3%2Bpt25cu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster) (1.26.4)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt25cu121\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.5.0+cu121.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt25cu121-cp310-cp310-linux_x86_64.whl (991 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m991.6/991.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.2+pt25cu121\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch-geometric) (0.2.0)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n",
            "Collecting e3nn\n",
            "  Downloading e3nn-0.5.4-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from e3nn) (1.13.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from e3nn) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from e3nn) (2.5.0+cu121)\n",
            "Collecting opt-einsum-fx>=0.1.4 (from e3nn)\n",
            "  Downloading opt_einsum_fx-0.1.4-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from opt-einsum-fx>=0.1.4->e3nn) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from opt-einsum-fx>=0.1.4->e3nn) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->e3nn) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->e3nn) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->e3nn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->e3nn) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->e3nn) (2024.10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->e3nn) (1.3.0)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->e3nn) (1.26.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->e3nn) (3.0.2)\n",
            "Downloading e3nn-0.5.4-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.2/447.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opt_einsum_fx-0.1.4-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: opt-einsum-fx, e3nn\n",
            "Successfully installed e3nn-0.5.4 opt-einsum-fx-0.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-blRgMtmIVzO"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KZ9oXthIadX"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HE4xlTGwoXqe",
        "outputId": "25419cd7-9fe9-47d2-ae08-d19f10f90a4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "import torch_geometric.loader as loader\n",
        "from torch_geometric.utils import to_undirected\n",
        "import e3nn\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "\n",
        "print(\"PyTorch version {}\".format(torch.__version__))\n",
        "print(\"PyG version {}\".format(torch_geometric.__version__))\n",
        "print(\"e3nn version {}\".format(e3nn.__version__))\n",
        "from models.schnet import SchNetModel\n",
        "from models.dimenet import DimeNetPPModel\n",
        "from models.spherenet import SphereNetModel\n",
        "from models.egnn import EGNNModel\n",
        "from experiments.utils.plot_utils import plot_2d, plot_3d\n",
        "from experiments.utils.data import create_kchains,create_pairA,create_pairB\n",
        "from experiments.utils.train_utils import run_experiment\n",
        "from models.schnet import SchNetModel\n",
        "from models.dimenet import DimeNetPPModel\n",
        "from models.spherenet import SphereNetModel\n",
        "from models.egnn import EGNNModel\n",
        "from models.gvpgnn import GVPGNNModel\n",
        "from models.tfn import TFNModel\n",
        "from models.mace import MACEModel\n",
        "# Set the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version 2.5.0+cu121\n",
            "PyG version 2.6.1\n",
            "e3nn version 0.5.4\n",
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "k_chain experiments.\n",
        "We first show our model can distinguish 12-chain paths using 7 blocks.\n",
        "Then, we show we can separate pair A in the paper.\n",
        "Then, we show we can separate pair B in the paper.\n",
        "\"\"\"\n",
        "import our_exps.utils\n",
        "from our_exps.utils import train_type_n_times\n",
        "\n",
        "num_times = 10\n",
        "\n",
        "train_k_chain = True\n",
        "\n",
        "train_pair_A = True\n",
        "\n",
        "train_pair_B = True\n",
        "\n",
        "if train_k_chain:\n",
        "    print(\"First we train our model to distinguish 12-chain graphs using 7 blocks(minimal)\")\n",
        "\n",
        "    acc = train_type_n_times(types='k_chain', task='classify_original', metric_track='loss',epochs = 200,num_times = 10)\n",
        "\n",
        "    print(f\"The accuracy is {acc[0]*100}%, over {num_times} different seeds\")\n",
        "\n",
        "    print(\"Succeeding distinguishing the k-chain experiment using 7 blocks\")\n",
        "    input(\"Press Enter to continue fot Pair A\")\n",
        "\n",
        "if train_pair_A:\n",
        "    acc = train_type_n_times(types='k_chain', task='classify_pair_A', metric_track='loss',epochs = 200,num_times = 10)\n",
        "\n",
        "    print(f\"The accuracy is {acc[0]*100}%, over {num_times} different seeds\")\n",
        "\n",
        "    print(\"Succeeding distinguishing Pair A, we now continuing to Pair B\")\n",
        "    input(\"Press Enter to continue fot Pair B\")\n",
        "if train_pair_B:\n",
        "    acc = train_type_n_times(types='k_chain', task='classify_pair_B', metric_track='loss',epochs = 200,num_times = 10)\n",
        "\n",
        "    print(f\"The accuracy is {acc[0]*100}%, over {num_times} different seeds\")\n",
        "\n",
        "    print(\"Succeeding distinguishing Pair B, we are done!\")"
      ],
      "metadata": {
        "id": "iyU2hUOiiDez",
        "outputId": "58e2c6ca-5745-4758-8802-07429ce63df6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'our_exps'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ba153a0934f2>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mThen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mshow\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mseparate\u001b[0m \u001b[0mpair\u001b[0m \u001b[0mB\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpaper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \"\"\"\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mour_exps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mour_exps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_type_n_times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'our_exps'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pl9qBnAm7Z6"
      },
      "source": [
        "# Propogating geometric information: $k$-chains\n",
        "In the first set of experiments we test the original $k$-chains for  $k$=4. Our aim is to examine short dependences of several models.\n",
        "For that we run the desired model with increasing number of blocks and report the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WApjQ_RroXqg"
      },
      "source": [
        "k = 4\n",
        "ntimes = 10\n",
        "\n",
        "# Create dataset\n",
        "dataset = create_kchains(k=k)\n",
        "for data in dataset:\n",
        "    plot_2d(data, lim=60)\n",
        "\n",
        "# Create dataloaders\n",
        "dataloader = loader.DataLoader(dataset, batch_size=1)\n",
        "val_loader = loader.DataLoader(dataset, batch_size=1)\n",
        "test_loader = loader.DataLoader(dataset, batch_size=1)\n",
        "# Set model\n",
        "model_name = \"EGNN\"\n",
        "\n",
        "for num_layers in range(3 , 7):\n",
        "\n",
        "    correlation = 2\n",
        "    model = {\n",
        "        \"SchNet\": SchNetModel,\n",
        "        \"dimenet\": DimeNetPPModel,\n",
        "        \"spherenet\": SphereNetModel,\n",
        "        \"EGNN\": EGNNModel,\n",
        "        \"GVP\": partial(GVPGNNModel, s_dim=32, v_dim=1),\n",
        "        \"TFN\": TFNModel,\n",
        "        \"MACE\": partial(MACEModel, correlation=correlation),\n",
        "    }[model_name](num_layers=num_layers, in_dim=1, out_dim=2)\n",
        "\n",
        "    best_val_acc_list, test_acc_list, train_time_list = run_experiment(\n",
        "        model,\n",
        "        dataloader,\n",
        "        val_loader,\n",
        "        test_loader,\n",
        "        n_epochs=150,\n",
        "        n_times=ntimes,\n",
        "        device=device,\n",
        "        verbose=False\n",
        "    )\n",
        "    print(f'\\nDone! Averaged over {ntimes} runs of {model_name} with {num_layers} layers: \\n '\n",
        "          f'- Training time: {np.mean(train_time_list):.2f}s ± {np.std(train_time_list):.2f}. \\n '\n",
        "          f'- Best validation accuracy: {np.mean(best_val_acc_list):.3f} ± {np.std(best_val_acc_list):.2f}. \\n'\n",
        "          f'- Test accuracy: {np.mean(test_acc_list):.1f} ± {np.std(test_acc_list):.1f}. \\n')"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Propogating geometric information: higher depth.\n",
        "\n",
        "In the second set of experiments we test the original $k$-chains for $k$=12. Our aim is to examine long dependences of several models.\n",
        "For that we run the desired model with increasing number of blocks and report the results."
      ],
      "metadata": {
        "id": "loM2_bElDVkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 12\n",
        "ntimes = 10\n",
        "\n",
        "# Create dataset\n",
        "dataset = create_kchains(k=k)\n",
        "for data in dataset:\n",
        "    plot_2d(data, lim=60)\n",
        "\n",
        "# Create dataloaders\n",
        "dataloader = loader.DataLoader(dataset, batch_size=1)\n",
        "val_loader = loader.DataLoader(dataset, batch_size=1)\n",
        "test_loader = loader.DataLoader(dataset, batch_size=1)\n",
        "# Set model\n",
        "model_name = \"EGNN\"\n",
        "\n",
        "for num_layers in range(7, 11):\n",
        "\n",
        "    correlation = 2\n",
        "    model = {\n",
        "        \"SchNet\": SchNetModel,\n",
        "        \"dimenet\": DimeNetPPModel,\n",
        "        \"spherenet\": SphereNetModel,\n",
        "        \"EGNN\": EGNNModel,\n",
        "        \"GVP\": partial(GVPGNNModel, s_dim=32, v_dim=1),\n",
        "        \"TFN\": TFNModel,\n",
        "        \"MACE\": partial(MACEModel, correlation=correlation),\n",
        "    }[model_name](num_layers=num_layers, in_dim=1, out_dim=2)\n",
        "\n",
        "    best_val_acc_list, test_acc_list, train_time_list = run_experiment(\n",
        "        model,\n",
        "        dataloader,\n",
        "        val_loader,\n",
        "        test_loader,\n",
        "        n_epochs=150,\n",
        "        n_times=ntimes,\n",
        "        device=device,\n",
        "        verbose=False\n",
        "    )\n",
        "    print(f'\\nDone! Averaged over {ntimes} runs of {model_name} with {num_layers} layers: \\n '\n",
        "          f'- Training time: {np.mean(train_time_list):.2f}s ± {np.std(train_time_list):.2f}. \\n '\n",
        "          f'- Best validation accuracy: {np.mean(best_val_acc_list):.3f} ± {np.std(best_val_acc_list):.2f}. \\n'\n",
        "          f'- Test accuracy: {np.mean(test_acc_list):.1f} ± {np.std(test_acc_list):.1f}. \\n')"
      ],
      "metadata": {
        "id": "cWvNoFOPDVuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHJIDDK5Inm3"
      },
      "source": [
        "# Power graph experiments.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8A03vrQJaB7"
      },
      "source": [
        "# First Pair.\n",
        "In this section, we show the seperation ability of invariant models depending on the power graph. In this experiment, we show no I-GGNN can sepearte the first power $G^{1}$, but can $G^{2}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DpfG6gIoXqg"
      },
      "source": [
        "ntimes= 10\n",
        "k = 8\n",
        "\n",
        "# Create dataset\n",
        "for power in [1,2]:\n",
        "  dataset = create_pairA(k=k,power = power)\n",
        "  print(f\"The graph power {power}\")\n",
        "  for data in dataset:\n",
        "      plot_2d(data, lim=6.0)\n",
        "\n",
        "  # Create dataloaders\n",
        "  dataloader = loader.DataLoader(dataset, batch_size=1)\n",
        "  val_loader = loader.DataLoader(dataset, batch_size=1)\n",
        "  test_loader = loader.DataLoader(dataset, batch_size=1)\n",
        "  # Set model\n",
        "  model_name = \"schnet\"\n",
        "\n",
        "  for num_layers in range(5 , 8):\n",
        "\n",
        "      print(f\"\\nNumber of layers: {num_layers}\")\n",
        "\n",
        "      correlation = 2\n",
        "      model = {\n",
        "          \"schnet\": SchNetModel,\n",
        "          \"dimenet\": DimeNetPPModel,\n",
        "          \"spherenet\": SphereNetModel\n",
        "      }[model_name](num_layers=num_layers, in_dim=1, out_dim=2)\n",
        "\n",
        "      best_val_acc_list, test_acc_list, train_time_list = run_experiment(\n",
        "        model,\n",
        "        dataloader,\n",
        "        val_loader,\n",
        "        test_loader,\n",
        "        n_epochs=150,\n",
        "        n_times=ntimes,\n",
        "        device=device,\n",
        "        verbose=False\n",
        "    )\n",
        "      print(f'\\nDone! Averaged over {ntimes} runs of {model_name} with {num_layers} layers, power graph {power}: \\n '\n",
        "          f'- Training time: {np.mean(train_time_list):.2f}s ± {np.std(train_time_list):.2f}. \\n '\n",
        "          f'- Best validation accuracy: {np.mean(best_val_acc_list):.3f} ± {np.std(best_val_acc_list):.3f}. \\n'\n",
        "          f'- Test accuracy: {np.mean(test_acc_list):.1f} ± {np.std(test_acc_list):.1f}. \\n')"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5yt2WVwJQpX"
      },
      "source": [
        "# Second Pair.\n",
        "In this section, we show the seperation ability of the model depending on the power graph. In this experiment, we show no I-GGNN can sepearte the first power and second but third could be separated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixrPtEw3JQ4e"
      },
      "source": [
        "ntimes= 10\n",
        "k = 8\n",
        "\n",
        "# Create dataset\n",
        "for power in [1,2,3]:\n",
        "  dataset = create_pairB(k=k,power = power)\n",
        "  print(f\"The graph power {power}\")\n",
        "  for data in dataset:\n",
        "      plot_2d(data, lim=6.0)\n",
        "\n",
        "  # Create dataloaders\n",
        "  dataloader = loader.DataLoader(dataset, batch_size=1)\n",
        "  val_loader = loader.DataLoader(dataset, batch_size=1)\n",
        "  test_loader = loader.DataLoader(dataset, batch_size=1)\n",
        "  # Set model\n",
        "  model_name = \"schnet\"\n",
        "\n",
        "  for num_layers in range(5 , 7):\n",
        "\n",
        "      print(f\"\\nNumber of layers: {num_layers}\")\n",
        "\n",
        "      correlation = 2\n",
        "      model = {\n",
        "          \"schnet\": SchNetModel,\n",
        "          \"dimenet\": DimeNetPPModel,\n",
        "          \"spherenet\": SphereNetModel\n",
        "      }[model_name](num_layers=num_layers, in_dim=1, out_dim=2)\n",
        "\n",
        "      best_val_acc_list, test_acc_list, train_time_list = run_experiment(\n",
        "        model,\n",
        "        dataloader,\n",
        "        val_loader,\n",
        "        test_loader,\n",
        "        n_epochs=150,\n",
        "        n_times=ntimes,\n",
        "        device=device,\n",
        "        verbose=False\n",
        "    )\n",
        "      print(f'\\nDone! Averaged over {ntimes} runs of {model_name} with {num_layers} layers, power graph {power}: \\n '\n",
        "          f'- Training time: {np.mean(train_time_list):.2f}s ± {np.std(train_time_list):.2f}. \\n '\n",
        "          f'- Best validation accuracy: {np.mean(best_val_acc_list):.3f} ± {np.std(best_val_acc_list):.3f}. \\n'\n",
        "          f'- Test accuracy: {np.mean(test_acc_list):.1f} ± {np.std(test_acc_list):.1f}. \\n')"
      ],
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "94aa676993820a604ac86f7af94f5432e989a749d5dd43e18f9507de2e8c2897"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
=======
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yonatansverdlov/E-GenNet/blob/master/k_chains_baselines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9vrEsxpYnlV"
   },
   "source": [
    "\n",
    "# Disseminating geometric data: $k$-chains\n",
    "Context:\n",
    "In geometric graph neural networks (GNNs), the transmission of geometric data, like the relative positioning of local neighborhoods, occurs through the aggregation of features across multiple layers within fixed-dimensional spaces. Ideally, an architecture capable of operating across any number of layers would perfectly transmit geometric data without any loss. However, in practice, stacking geometric GNN layers can introduce distortions or result in the loss of information from distant nodes.\n",
    "\n",
    "Experimental Setup:\n",
    "To investigate the practical implications of depth in transmitting geometric information beyond local neighborhoods, we examine $k$-chain geometric graphs, a concept extending from examples discussed in Schütt et al., 2021. Each $k$-chain consists of $k+2$ nodes, with $k$ nodes arranged linearly and distinguished by the orientation of the $2$ endpoints. Consequently, $k$-chain graphs are $(\\lfloor \\frac{k}{2} \\rfloor + 1)$-hop distinguishable, and theoretically, $(\\lfloor \\frac{k}{2} \\rfloor + 1)$ iterations of geometric GNNs should suffice for their discrimination. Within this study, we train equivariant and invariant geometric GNNs, increasing the number of layers, to differentiate $k$-chains.\n",
    "\n",
    "Additionally, we explore the impact of power graphs in scenarios where I-GGNNs are unable to distinguish between graphs. Specifically, we examine pairs of graphs depicted in the figure. In Pair A, theoretically, there is insufficient information to distinguish between $G_{1}$ and $G_{2}$, but there is adequate information in $G_{1}^{2}$ and $G_{2}^{2}$. In Pair B, theoretically, there is insufficient information to distinguish between $(G_{1}, G_{2})$ and $(G_{1}^{2}, G_{2}^{2})$, but there is adequate information in $(G_{1}^{3}, G_{2}^{3})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MRHVAc977fJx",
    "outputId": "1755b511-a1b0-4b8f-9952-8a82a89d1b01"
   },
   "source": [
    "from google.colab import drive\n",
    "import sys\n",
    "drive.mount('/content/drive')\n",
    "# We expact the k_chain_exps directory to be in that place.\n",
    "\n",
    "!git clone https://github.com/yonatansverdlov/E-GenNet\n",
    "sys.path.append('/content/E-GenNet/k_chain_exps')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Install Packages."
   ],
   "metadata": {
    "id": "7QoUhPwJ6Bwm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HqIeByYsapfb",
    "collapsed": true,
    "outputId": "6973a363-5627-48f2-9163-f094b13ed58c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# Add this in a Google Colab cell to install the correct version of Pytorch Geometric.\n",
    "import torch\n",
    "\n",
    "def format_pytorch_version(version):\n",
    "  return version.split('+')[0]\n",
    "\n",
    "TORCH_version = torch.__version__\n",
    "TORCH = format_pytorch_version(TORCH_version)\n",
    "\n",
    "def format_cuda_version(version):\n",
    "  return 'cu' + version.replace('.', '')\n",
    "\n",
    "CUDA_version = torch.version.cuda\n",
    "CUDA = format_cuda_version(CUDA_version)\n",
    "\n",
    "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "!pip install torch-geometric\n",
    "!pip install e3nn\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-blRgMtmIVzO"
   },
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KZ9oXthIadX"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HE4xlTGwoXqe",
    "outputId": "df02e8b1-9c92-4c23-c9fe-0166f051b1bc",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.loader as loader\n",
    "from torch_geometric.utils import to_undirected\n",
    "import e3nn\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "print(\"PyTorch version {}\".format(torch.__version__))\n",
    "print(\"PyG version {}\".format(torch_geometric.__version__))\n",
    "print(\"e3nn version {}\".format(e3nn.__version__))\n",
    "from models.schnet import SchNetModel\n",
    "from models.dimenet import DimeNetPPModel\n",
    "from models.spherenet import SphereNetModel\n",
    "from models.egnn import EGNNModel\n",
    "from experiments.utils.plot_utils import plot_2d, plot_3d\n",
    "from experiments.utils.data import create_kchains,create_pairA,create_pairB\n",
    "from experiments.utils.train_utils import run_experiment\n",
    "from models.schnet import SchNetModel\n",
    "from models.dimenet import DimeNetPPModel\n",
    "from models.spherenet import SphereNetModel\n",
    "from models.egnn import EGNNModel\n",
    "from models.gvpgnn import GVPGNNModel\n",
    "from models.tfn import TFNModel\n",
    "from models.mace import MACEModel\n",
    "# Set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8pl9qBnAm7Z6"
   },
   "source": [
    "# Propogating geometric information: $k$-chains\n",
    "In the first set of experiments we test the original $k$-chains for  $k$=4. Our aim is to examine short dependences of several models.\n",
    "For that we run the desired model with increasing number of blocks and report the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WApjQ_RroXqg",
    "outputId": "5db15a28-4d50-4df4-d82d-f2db44c4cb85",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "e7cc62ca9e144fec8159426a7a9ca83c",
      "868bbdd7b70f4ef0b4f55f07ae11fa0b",
      "decccdfc29dd421f8ba91d3347654bbc",
      "75664a9ecb4e4adfb0391b41c8a48ed0",
      "e2149286f79546f391053cf2c5b3d629",
      "23b33107edee46c2a8aa57777110f3f2",
      "d38492085933426da1b132a15cb184d2",
      "90824bd3b5de471191880a9a29c261b2",
      "68c28cb139c34e2aa047957e244f85b2",
      "27ffa6d47a944853a4c124c52e87510b",
      "ff42783d9c8e4bca9cbbdc55dd24b435",
      "129fe7c38a7f411197f1ccda44ab2bf7",
      "ecec6cab9dcf4e3bb91e41f42fc6e725",
      "cfd3ccbc15134ac78fb581cb1f6ef282",
      "2682d75df85e4bd8b6c057afcc39f13f",
      "16d678fd75bb4e77ba42e5e8e3d30a88",
      "91bae917de8f47d292af7c3404b713a3",
      "0c41d79db51d423db100410a15e74601",
      "63f4374c7d7a4177916210de4ee943fd",
      "48c4c19ee9d343b6b526519da9078acf",
      "972804a709a84e2c867462b06f926174",
      "247a4377d8f54f3691ce10d95e615344"
     ]
    }
   },
   "source": [
    "k = 4\n",
    "ntimes = 10\n",
    "\n",
    "# Create dataset\n",
    "dataset = create_kchains(k=k)\n",
    "for data in dataset:\n",
    "    plot_2d(data, lim=60)\n",
    "\n",
    "# Create dataloaders\n",
    "dataloader = loader.DataLoader(dataset, batch_size=1)\n",
    "val_loader = loader.DataLoader(dataset, batch_size=1)\n",
    "test_loader = loader.DataLoader(dataset, batch_size=1)\n",
    "# Set model\n",
    "model_name = \"EGNN\"\n",
    "\n",
    "for num_layers in range(3 , 7):\n",
    "\n",
    "    correlation = 2\n",
    "    model = {\n",
    "        \"SchNet\": SchNetModel,\n",
    "        \"dimenet\": DimeNetPPModel,\n",
    "        \"spherenet\": SphereNetModel,\n",
    "        \"EGNN\": EGNNModel,\n",
    "        \"GVP\": partial(GVPGNNModel, s_dim=32, v_dim=1),\n",
    "        \"TFN\": TFNModel,\n",
    "        \"MACE\": partial(MACEModel, correlation=correlation),\n",
    "    }[model_name](num_layers=num_layers, in_dim=1, out_dim=2)\n",
    "\n",
    "    best_val_acc_list, test_acc_list, train_time_list = run_experiment(\n",
    "        model,\n",
    "        dataloader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        n_epochs=150,\n",
    "        n_times=ntimes,\n",
    "        device=device,\n",
    "        verbose=False\n",
    "    )\n",
    "    print(f'\\nDone! Averaged over {ntimes} runs of {model_name} with {num_layers} layers: \\n '\n",
    "          f'- Training time: {np.mean(train_time_list):.2f}s ± {np.std(train_time_list):.2f}. \\n '\n",
    "          f'- Best validation accuracy: {np.mean(best_val_acc_list):.3f} ± {np.std(best_val_acc_list):.2f}. \\n'\n",
    "          f'- Test accuracy: {np.mean(test_acc_list):.1f} ± {np.std(test_acc_list):.1f}. \\n')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Propogating geometric information: higher depth.\n",
    "\n",
    "In the second set of experiments we test the original $k$-chains for $k$=12. Our aim is to examine long dependences of several models.\n",
    "For that we run the desired model with increasing number of blocks and report the results."
   ],
   "metadata": {
    "id": "loM2_bElDVkc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "k = 12\n",
    "ntimes = 10\n",
    "\n",
    "# Create dataset\n",
    "dataset = create_kchains(k=k)\n",
    "for data in dataset:\n",
    "    plot_2d(data, lim=60)\n",
    "\n",
    "# Create dataloaders\n",
    "dataloader = loader.DataLoader(dataset, batch_size=1)\n",
    "val_loader = loader.DataLoader(dataset, batch_size=1)\n",
    "test_loader = loader.DataLoader(dataset, batch_size=1)\n",
    "# Set model\n",
    "model_name = \"EGNN\"\n",
    "\n",
    "for num_layers in range(7, 11):\n",
    "\n",
    "    correlation = 2\n",
    "    model = {\n",
    "        \"SchNet\": SchNetModel,\n",
    "        \"dimenet\": DimeNetPPModel,\n",
    "        \"spherenet\": SphereNetModel,\n",
    "        \"EGNN\": EGNNModel,\n",
    "        \"GVP\": partial(GVPGNNModel, s_dim=32, v_dim=1),\n",
    "        \"TFN\": TFNModel,\n",
    "        \"MACE\": partial(MACEModel, correlation=correlation),\n",
    "    }[model_name](num_layers=num_layers, in_dim=1, out_dim=2)\n",
    "\n",
    "    best_val_acc_list, test_acc_list, train_time_list = run_experiment(\n",
    "        model,\n",
    "        dataloader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        n_epochs=150,\n",
    "        n_times=ntimes,\n",
    "        device=device,\n",
    "        verbose=False\n",
    "    )\n",
    "    print(f'\\nDone! Averaged over {ntimes} runs of {model_name} with {num_layers} layers: \\n '\n",
    "          f'- Training time: {np.mean(train_time_list):.2f}s ± {np.std(train_time_list):.2f}. \\n '\n",
    "          f'- Best validation accuracy: {np.mean(best_val_acc_list):.3f} ± {np.std(best_val_acc_list):.2f}. \\n'\n",
    "          f'- Test accuracy: {np.mean(test_acc_list):.1f} ± {np.std(test_acc_list):.1f}. \\n')"
   ],
   "metadata": {
    "id": "cWvNoFOPDVuV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHJIDDK5Inm3"
   },
   "source": [
    "# Power graph experiments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8A03vrQJaB7"
   },
   "source": [
    "# First Pair.\n",
    "In this section, we show the seperation ability of invariant models depending on the power graph. In this experiment, we show no I-GGNN can sepearte the first power $G^{1}$, but can $G^{2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DpfG6gIoXqg"
   },
   "source": [
    "ntimes= 10\n",
    "k = 8\n",
    "\n",
    "# Create dataset\n",
    "for power in [1,2]:\n",
    "  dataset = create_pairA(k=k,power = power)\n",
    "  print(f\"The graph power {power}\")\n",
    "  for data in dataset:\n",
    "      plot_2d(data, lim=6.0)\n",
    "\n",
    "  # Create dataloaders\n",
    "  dataloader = loader.DataLoader(dataset, batch_size=1)\n",
    "  val_loader = loader.DataLoader(dataset, batch_size=1)\n",
    "  test_loader = loader.DataLoader(dataset, batch_size=1)\n",
    "  # Set model\n",
    "  model_name = \"schnet\"\n",
    "\n",
    "  for num_layers in range(5 , 8):\n",
    "\n",
    "      print(f\"\\nNumber of layers: {num_layers}\")\n",
    "\n",
    "      correlation = 2\n",
    "      model = {\n",
    "          \"schnet\": SchNetModel,\n",
    "          \"dimenet\": DimeNetPPModel,\n",
    "          \"spherenet\": SphereNetModel\n",
    "      }[model_name](num_layers=num_layers, in_dim=1, out_dim=2)\n",
    "\n",
    "      best_val_acc_list, test_acc_list, train_time_list = run_experiment(\n",
    "        model,\n",
    "        dataloader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        n_epochs=150,\n",
    "        n_times=ntimes,\n",
    "        device=device,\n",
    "        verbose=False\n",
    "    )\n",
    "      print(f'\\nDone! Averaged over {ntimes} runs of {model_name} with {num_layers} layers, power graph {power}: \\n '\n",
    "          f'- Training time: {np.mean(train_time_list):.2f}s ± {np.std(train_time_list):.2f}. \\n '\n",
    "          f'- Best validation accuracy: {np.mean(best_val_acc_list):.3f} ± {np.std(best_val_acc_list):.3f}. \\n'\n",
    "          f'- Test accuracy: {np.mean(test_acc_list):.1f} ± {np.std(test_acc_list):.1f}. \\n')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5yt2WVwJQpX"
   },
   "source": [
    "# Second Pair.\n",
    "In this section, we show the seperation ability of the model depending on the power graph. In this experiment, we show no I-GGNN can sepearte the first power and second but third could be separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixrPtEw3JQ4e"
   },
   "source": [
    "ntimes= 10\n",
    "k = 8\n",
    "\n",
    "# Create dataset\n",
    "for power in [1,2,3]:\n",
    "  dataset = create_pairB(k=k,power = power)\n",
    "  print(f\"The graph power {power}\")\n",
    "  for data in dataset:\n",
    "      plot_2d(data, lim=6.0)\n",
    "\n",
    "  # Create dataloaders\n",
    "  dataloader = loader.DataLoader(dataset, batch_size=1)\n",
    "  val_loader = loader.DataLoader(dataset, batch_size=1)\n",
    "  test_loader = loader.DataLoader(dataset, batch_size=1)\n",
    "  # Set model\n",
    "  model_name = \"schnet\"\n",
    "\n",
    "  for num_layers in range(5 , 7):\n",
    "\n",
    "      print(f\"\\nNumber of layers: {num_layers}\")\n",
    "\n",
    "      correlation = 2\n",
    "      model = {\n",
    "          \"schnet\": SchNetModel,\n",
    "          \"dimenet\": DimeNetPPModel,\n",
    "          \"spherenet\": SphereNetModel\n",
    "      }[model_name](num_layers=num_layers, in_dim=1, out_dim=2)\n",
    "\n",
    "      best_val_acc_list, test_acc_list, train_time_list = run_experiment(\n",
    "        model,\n",
    "        dataloader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        n_epochs=150,\n",
    "        n_times=ntimes,\n",
    "        device=device,\n",
    "        verbose=False\n",
    "    )\n",
    "      print(f'\\nDone! Averaged over {ntimes} runs of {model_name} with {num_layers} layers, power graph {power}: \\n '\n",
    "          f'- Training time: {np.mean(train_time_list):.2f}s ± {np.std(train_time_list):.2f}. \\n '\n",
    "          f'- Best validation accuracy: {np.mean(best_val_acc_list):.3f} ± {np.std(best_val_acc_list):.3f}. \\n'\n",
    "          f'- Test accuracy: {np.mean(test_acc_list):.1f} ± {np.std(test_acc_list):.1f}. \\n')"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "94aa676993820a604ac86f7af94f5432e989a749d5dd43e18f9507de2e8c2897"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "e7cc62ca9e144fec8159426a7a9ca83c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_868bbdd7b70f4ef0b4f55f07ae11fa0b",
       "IPY_MODEL_decccdfc29dd421f8ba91d3347654bbc",
       "IPY_MODEL_75664a9ecb4e4adfb0391b41c8a48ed0"
      ],
      "layout": "IPY_MODEL_e2149286f79546f391053cf2c5b3d629"
     }
    },
    "868bbdd7b70f4ef0b4f55f07ae11fa0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23b33107edee46c2a8aa57777110f3f2",
      "placeholder": "​",
      "style": "IPY_MODEL_d38492085933426da1b132a15cb184d2",
      "value": "100%"
     }
    },
    "decccdfc29dd421f8ba91d3347654bbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90824bd3b5de471191880a9a29c261b2",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_68c28cb139c34e2aa047957e244f85b2",
      "value": 10
     }
    },
    "75664a9ecb4e4adfb0391b41c8a48ed0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27ffa6d47a944853a4c124c52e87510b",
      "placeholder": "​",
      "style": "IPY_MODEL_ff42783d9c8e4bca9cbbdc55dd24b435",
      "value": " 10/10 [01:19&lt;00:00,  7.15s/it]"
     }
    },
    "e2149286f79546f391053cf2c5b3d629": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23b33107edee46c2a8aa57777110f3f2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d38492085933426da1b132a15cb184d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "90824bd3b5de471191880a9a29c261b2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68c28cb139c34e2aa047957e244f85b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "27ffa6d47a944853a4c124c52e87510b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff42783d9c8e4bca9cbbdc55dd24b435": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "129fe7c38a7f411197f1ccda44ab2bf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ecec6cab9dcf4e3bb91e41f42fc6e725",
       "IPY_MODEL_cfd3ccbc15134ac78fb581cb1f6ef282",
       "IPY_MODEL_2682d75df85e4bd8b6c057afcc39f13f"
      ],
      "layout": "IPY_MODEL_16d678fd75bb4e77ba42e5e8e3d30a88"
     }
    },
    "ecec6cab9dcf4e3bb91e41f42fc6e725": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91bae917de8f47d292af7c3404b713a3",
      "placeholder": "​",
      "style": "IPY_MODEL_0c41d79db51d423db100410a15e74601",
      "value": " 30%"
     }
    },
    "cfd3ccbc15134ac78fb581cb1f6ef282": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63f4374c7d7a4177916210de4ee943fd",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_48c4c19ee9d343b6b526519da9078acf",
      "value": 3
     }
    },
    "2682d75df85e4bd8b6c057afcc39f13f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_972804a709a84e2c867462b06f926174",
      "placeholder": "​",
      "style": "IPY_MODEL_247a4377d8f54f3691ce10d95e615344",
      "value": " 3/10 [00:25&lt;00:59,  8.53s/it]"
     }
    },
    "16d678fd75bb4e77ba42e5e8e3d30a88": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91bae917de8f47d292af7c3404b713a3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c41d79db51d423db100410a15e74601": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "63f4374c7d7a4177916210de4ee943fd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48c4c19ee9d343b6b526519da9078acf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "972804a709a84e2c867462b06f926174": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "247a4377d8f54f3691ce10d95e615344": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
>>>>>>> Reinitialize egenet repository after moving
